INFO 02-08 03:36:28 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 02-08 03:36:33 llm_engine.py:207] # GPU blocks: 7445, # CPU blocks: 2048
task201 test: 0.399
task201 eval: 0.365
task1386 test: 0.3142857142857143
task1386 eval: 0.3673469387755102
task738 test: 0.574
task738 eval: 0.546
task1529 test: 0.098
task1529 eval: 0.087
task1612 test: 0.513
task1612 eval: 0.51625
task1516 test: 0.15714285714285714
task1516 eval: 0.19428571428571428
