[2023-11-28 22:56:52,682] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
task957
searching parameters: task957_30_20_45_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_45_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_45_0.8_0.3_3_1/config.json
generate_and_write_inputs!
INFO 11-28 22:56:59 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 22:57:16 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:00:45 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:01:02 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 600
selection_ratio: 0.0
searching parameters: task957_30_20_50_0.8_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.4_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:04:05 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:04:19 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:07:42 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:07:57 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 600
selection_ratio: 0.0
searching parameters: task957_30_15_45_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_15_45_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_15_45_0.8_0.3_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:10:56 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:11:11 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:14:19 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:14:33 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 450
selection_ratio: 0.0
searching parameters: task957_20_20_45_0.6_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_20_20_45_0.6_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_20_20_45_0.6_0.3_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:16:58 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:17:13 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:19:32 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:19:47 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 400
selection_ratio: 0.0
searching parameters: task957_20_15_50_0.4_0.35_3_1
/home/cyzhao/NI_task957_exp_1/task957_20_15_50_0.4_0.35_3_1
/home/cyzhao/NI_task957_exp_1/task957_20_15_50_0.4_0.35_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:21:41 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:21:56 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:23:37 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:23:52 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 300
selection_ratio: 0.0
searching parameters: task957_30_10_40_0.5_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_10_40_0.5_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_10_40_0.5_0.4_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:24:44 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:24:59 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:27:13 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:27:30 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 300
selection_ratio: 0.0
searching parameters: task957_30_10_50_0.5_0.35_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_10_50_0.5_0.35_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_10_50_0.5_0.35_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:28:36 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:28:50 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:30:47 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:31:02 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 300
selection_ratio: 0.0
searching parameters: task957_10_20_40_0.7_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_10_20_40_0.7_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_10_20_40_0.7_0.4_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:32:11 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:32:26 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:33:22 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:33:37 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 200
selection_ratio: 0.0
searching parameters: task957_10_20_40_0.6_0.35_3_1
/home/cyzhao/NI_task957_exp_1/task957_10_20_40_0.6_0.35_3_1
/home/cyzhao/NI_task957_exp_1/task957_10_20_40_0.6_0.35_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:34:39 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:34:53 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:36:05 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:36:20 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 200
selection_ratio: 0.0
searching parameters: task957_10_20_45_0.7_0.35_3_1
/home/cyzhao/NI_task957_exp_1/task957_10_20_45_0.7_0.35_3_1
/home/cyzhao/NI_task957_exp_1/task957_10_20_45_0.7_0.35_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:37:26 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:37:40 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:38:50 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:39:04 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 200
selection_ratio: 0.0
searching parameters: task957_30_15_45_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_15_45_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_15_45_0.8_0.3_3_1/config.json
searching parameters: task957_30_20_50_0.8_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.4_3_1/config.json
searching parameters: task957_30_20_50_0.8_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.4_3_1/config.json
searching parameters: task957_30_20_50_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.3_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:40:06 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:40:23 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:43:43 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:44:00 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 600
selection_ratio: 0.0
searching parameters: task957_30_20_45_0.4_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_45_0.4_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_45_0.4_0.4_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:47:06 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:47:22 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:50:13 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:50:27 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 600
selection_ratio: 0.0
searching parameters: task957_20_10_45_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_20_10_45_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_20_10_45_0.8_0.3_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:52:20 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:52:34 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:54:22 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:54:36 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 200
selection_ratio: 0.0
searching parameters: task957_30_20_50_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.3_3_1/config.json
searching parameters: task957_30_20_50_0.8_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_30_20_50_0.8_0.4_3_1/config.json
searching parameters: task957_10_10_45_0.4_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_10_10_45_0.4_0.3_3_1
/home/cyzhao/NI_task957_exp_1/task957_10_10_45_0.4_0.3_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:55:42 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:55:57 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:56:47 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:57:01 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 100
selection_ratio: 0.0
searching parameters: task957_20_15_40_0.6_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_20_15_40_0.6_0.4_3_1
/home/cyzhao/NI_task957_exp_1/task957_20_15_40_0.6_0.4_3_1/config.json
generate_and_write_inputs!
INFO 11-28 23:57:26 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:57:41 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
annotate_and_write_outputs!
INFO 11-28 23:59:21 llm_engine.py:72] Initializing an LLM engine with config: model='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer='/data/ckpts/huggingface/models/models--deepseek-ai--deepseek-llm-7b-chat/snapshots/afbda8b347ec881666061fa67447046fc5164ec8', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)
INFO 11-28 23:59:36 llm_engine.py:207] # GPU blocks: 16502, # CPU blocks: 1024
generated_example_num: 0
expected_example_num: 300
selection_ratio: 0.0
{'generation_epochs': 30, 'generation_batch_size': 20, 'generation_top_k': 45, 'generation_temperature': 0.8, 'min_frequency': 0.3, 'training_epochs': 3}
test best ckpt.
